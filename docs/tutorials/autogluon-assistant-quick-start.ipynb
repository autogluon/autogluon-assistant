{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "998885f294556807",
   "metadata": {},
   "source": [
    "# AutoGluon Assistant - Quick Start\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/autogluon/autogluon-assistant)\n",
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://github.com/autogluon/autogluon-assistant)\n",
    "\n",
    "(Links above are still WIP)\n",
    "\n",
    "In this tutorial, we will see how to use AutoGluon Assistant (AG-A) to solve machine learning problems **with zero line of code**. AG-A combines the power of AutoGluon's state-of-the-art AutoML capabilities with Large Language Models (LLMs) to automate the entire data science pipeline.\n",
    "\n",
    "We will cover:\n",
    "- Setting up AutoGluon Assistant\n",
    "- Preparing your data\n",
    "- Running your first ML project using a toy version of Titanic dataset\n",
    "- Understanding the output and predictions\n",
    "- Customizing the configuration for better results\n",
    "\n",
    "By the end of this tutorial, you'll be able to transform your data and problem description into highly accurate ML solutions using just natural language instructions. Let's get started with the installation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06e8e04",
   "metadata": {},
   "source": [
    "## Setting up AutoGluon Assistant\n",
    "Getting started with AutoGluon Assistant is straightforward. Let's install it directly using pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d1edc3d2f610f6",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/autogluon/autogluon-assistant.git#egg=autogluon-assistant[dev]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4f6834",
   "metadata": {},
   "source": [
    "AutoGluon Assistant supports two LLM providers: AWS Bedrock (default) and OpenAI. Choose one of the following setups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff904c9d1af0ac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Option A: AWS Bedrock (Recommended)\n",
    "os.environ['BEDROCK_API_KEY'] = '4509...'\n",
    "os.environ['AWS_DEFAULT_REGION'] = '<your-region>'\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = '<your-access-key>'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = '<your-secret-key>'\n",
    "\n",
    "### OR ###\n",
    "\n",
    "# Option B: OpenAI\n",
    "os.environ['OPENAI_API_KEY'] = 'sk-...'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec461b5",
   "metadata": {},
   "source": [
    "*Note: If using OpenAI, we recommend a paid API key rather than a free-tier account to avoid rate limiting issues.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9e1754",
   "metadata": {},
   "source": [
    "Let's verify the installation by importing the package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce77f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogluon_assistant\n",
    "print(autogluon_assistant.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052f7fec",
   "metadata": {},
   "source": [
    "\n",
    "Now that you have AutoGluon Assistant installed and configured, let's move on to preparing your data directory structure for your first ML project!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42b07bc64929c80",
   "metadata": {},
   "source": [
    "## Example Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f247a5c20c9be613",
   "metadata": {},
   "source": [
    "For this tutorial, we'll use the classic Titanic dataset which is perfect for getting started with machine learning. The goal is to predict whether a passenger survived based on their characteristics such as age, gender, ticket class, and other features. We sampled 1000 training and test examples from the original data. The sampled dataset make this tutorial run quickly, but AutoGluon Assistant can handle the full dataset if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfda6620a2f2637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os\n",
    "\n",
    "# Create directory and download example files\n",
    "os.makedirs(\"./toy_data\", exist_ok=True)\n",
    "for f in [\"train.csv\", \"test.csv\", \"descriptions.txt\"]:\n",
    "    open(f\"toy_data/{f}\", \"wb\").write(\n",
    "        requests.get(f\"https://raw.githubusercontent.com/autogluon/autogluon-assistant/main/toy_data/{f}\").content\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c810125a2b8aa286",
   "metadata": {},
   "source": [
    "That's it! We now have:\n",
    "\n",
    "- `train.csv`: Training data with labeled examples\n",
    "- `test.csv`: Test data for making predictions\n",
    "- `descriptions.txt`: A description of the dataset and task\n",
    "\n",
    "Let's take a quick look at our training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735d0a050b701f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv(\"toy_data/train.csv\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8a61ef4291bc39",
   "metadata": {},
   "source": [
    "## Using AutoGluon Assistant\n",
    "\n",
    "Now that we have our data ready, let's use AutoGluon Assistant to build our ML model. The simplest way to use AutoGluon Assistant is through the command line - no coding required! After installing the package, you can run it directly from your terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bbf825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: remove the requirement of config files\n",
    "!autogluon-assistant ./toy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25c839d",
   "metadata": {},
   "source": [
    "Let's also look at how to use AutoGluon Assistant programmatically in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362ff589bb29d77d",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from autogluon_assistant import AutogluonAssistant\n",
    "\n",
    "# Initialize the assistant\n",
    "assistant = AutogluonAssistant()\n",
    "\n",
    "# Run the assistant\n",
    "output_file = assistant.predict(data_dir=\"./toy_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0c76c9931ef02a",
   "metadata": {},
   "source": [
    "Model fitting should take a few minutes or less depending on your CPU. You can make training faster by specifying the `time_limit` argument. For example, `fit(..., time_limit=60)` will stop training after 60 seconds. Higher time limits will generally result in better prediction performance, and excessively low time limits will prevent AutoGluon from training and ensembling a reasonable set of models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14b3b77951c8885",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "Once we have a predictor that is fit on the training dataset, we can load a separate set of data to use for prediction and evaulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c5ca4d79e46793",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TabularDataset(f'{data_url}test.csv')\n",
    "\n",
    "y_pred = predictor.predict(test_data.drop(columns=[label]))\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07dc2dd8e3225a",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We can evaluate the predictor on the test dataset using the `evaluate()` function, which measures how well our predictor performs on data that was not used for fitting the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d51e36939dcc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ad005fd976a13e",
   "metadata": {},
   "source": [
    "AutoGluon's `TabularPredictor` also provides the `leaderboard()` function, which allows us to evaluate the performance of each individual trained model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a52983e6d38da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eb2f75ce0e5eed",
   "metadata": {
    "id": "I-da0PXvpD96"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this quickstart tutorial we saw AutoGluon's basic fit and predict functionality using `TabularDataset` and `TabularPredictor`. AutoGluon simplifies the model training process by not requiring feature engineering or model hyperparameter tuning. Check out the in-depth tutorials to learn more about AutoGluon's other features like customizing the training and prediction steps or extending AutoGluon with custom feature generators, models, or metrics."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
